{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sat_1987_1998 = pd.read_excel('data/SAT_1987_1998.xls', skiprows=range(11))\n",
    "sat_2017_2018 = pd.read_excel('data/SAT_2017_2018.xls', skiprows=range(5))\n",
    "\n",
    "#2005-2015\n",
    "old_2006_2009 = pd.read_excel('data/2006_2009.xls', skiprows=range(3)) #<-- 2005,2007,2008,2009\n",
    "load_2006 = pd.read_excel('data/2006.xls', skiprows = range(6)) #<-- 2006\n",
    "sat_1995_2015 = pd.read_excel('data/SAT_1995_2015.xls', skiprows=range(3)) #<-- 2010, 2013, 2014\n",
    "load_2011_2012 = pd.read_excel('data/2010-2012.xls', skiprows=range(5)) #<-- 2011, 2012\n",
    "load_2015 = pd.read_excel('data/2015.xls', skiprows=range(5)) #<-- 2015\n",
    "\n",
    "\n",
    "#Remove unwanted rows and columns\n",
    "sat_2017 = sat_2017_2018.iloc[:-3, :8]\n",
    "sat_2018 = sat_2017_2018.iloc[:-3, 8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old SAT format: 2400 score. Lasted from 2005-2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering, splitting functions\n",
    "\n",
    "#Get the clean list of states from the DF.\n",
    "def clean_states(df:pd.DataFrame) -> list:\n",
    "    states_list = []\n",
    "    for i in df.iloc[:, 0]:\n",
    "        states_list.append(i.split('.')[0])\n",
    "        \n",
    "    return states_list\n",
    "\n",
    "#Cleaning up data and split the DF into respective years if applicable\n",
    "def clean_multi_dataset(df, renamed_col = ['State', 'Reading', 'Math', 'Writing']):\n",
    "    for i in range(1, len(df.columns) - 1, 3):\n",
    "        data_year = df.iloc[:,i:i+3]\n",
    "\n",
    "        data_year.insert(0, 'States', clean_states(df))\n",
    "        data_year.columns = renamed_col\n",
    "        data_year['SAT Total Score'] = data_year.apply(lambda row: row.Reading + row.Math + row.Writing, axis=1)\n",
    "\n",
    "        yield data_year\n",
    "    \n",
    "#For grabbing a single year out of the dataset:\n",
    "def clean_dataset(df, start, end, renamed_col = ['State', 'Reading', 'Math', 'Writing']):\n",
    "    data_year = df.iloc[:, start:end]\n",
    "\n",
    "    data_year.insert(0, 'States', clean_states(df))\n",
    "    data_year.columns = renamed_col\n",
    "    data_year['SAT Total Score'] = data_year.apply(lambda row: row.Reading + row.Math + row.Writing, axis=1)\n",
    "\n",
    "    return data_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean table of NaN rows and columns and nonuseful data.\n",
    "def remove_nan(df):\n",
    "    return df[pd.notnull(df.iloc[:,1])]\n",
    "\n",
    "#Ready for splitting and filtering:\n",
    "\n",
    "#For 2006\n",
    "data_2006 = remove_nan(load_2006)\n",
    "\n",
    "#For 2005, 2007, 2008, 2009\n",
    "old_2006_2009 = remove_nan(old_2006_2009).drop(columns=[2,3,4,5,18,19])\n",
    "\n",
    "#For 2010, 2013, 2014\n",
    "sat_1995_2015 = remove_nan(sat_1995_2015).drop(columns=[2,3,4,5,6,7,8,18,19])\n",
    "\n",
    "#For 2011, 2012\n",
    "\n",
    "#For 2015\n",
    "load_2015 = remove_nan(load_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Relevant tables for 2005-2010:\n",
    "cleaned_2005_2009 = clean_multi_dataset(old_2006_2009) #<-- 2005, 2007, 2008, 2009\n",
    "cleaned_10_13_14 = clean_multi_dataset(sat_1995_2015) #<-- 2010, 2013, 2014\n",
    "cleaned_11_12 = clean_multi_dataset(load_2011_2012) #<-- 2011, 2012\n",
    "\n",
    "# Data for 2005-2010:\n",
    "sat_2005 = next(cleaned_2005_2009)\n",
    "sat_2006 = clean_dataset(data_2006, 12, 15)\n",
    "sat_2007 = next(cleaned_2005_2009)\n",
    "sat_2008 = next(cleaned_2005_2009)\n",
    "sat_2009 = next(cleaned_2005_2009)\n",
    "# sat_2010 = next(cleaned_10_13_14)\n",
    "\n",
    "# #Data for 2011-2015:\n",
    "# sat_2011 = next(cleaned_11_12)\n",
    "# sat_2012 = next(cleaned_11_12)\n",
    "# sat_2013 = next(cleaned_10_13_14)\n",
    "# sat_2014 = next(cleaned_10_13_14)\n",
    "# sat_2015 = clean_dataset(load_2015, 14, 17)\n",
    "\n",
    "#Need 2011, 2012, 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States .....</td>\n",
       "      <td>505.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>484.0</td>\n",
       "      <td>48.055532</td>\n",
       "      <td>48.841478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama .......................</td>\n",
       "      <td>565.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>561.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>541.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>6.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska ........................</td>\n",
       "      <td>521.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>493.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>54.200000</td>\n",
       "      <td>51.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona ......................</td>\n",
       "      <td>525.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>521.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>36.400000</td>\n",
       "      <td>34.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas ......................</td>\n",
       "      <td>566.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>569.0</td>\n",
       "      <td>551.0</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>\\1\\Members of the graduating class who had tak...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>\\2\\The SAT is administered to all public high ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>\\3\\Beginning with the spring SAT administratio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NOTE: Data for 2005-06 and earlier years are f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>SOURCE: College Entrance Examination Board, Co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   1      2      3      4   \\\n",
       "0                                 United States .....  505.0  508.0  506.0   \n",
       "1                     Alabama .......................  565.0  558.0  559.0   \n",
       "2                     Alaska ........................  521.0  513.0  514.0   \n",
       "3                      Arizona ......................  525.0  521.0  523.0   \n",
       "4                     Arkansas ......................  566.0  550.0  562.0   \n",
       "..                                                ...    ...    ...    ...   \n",
       "62  \\1\\Members of the graduating class who had tak...    NaN    NaN    NaN   \n",
       "63  \\2\\The SAT is administered to all public high ...    NaN    NaN    NaN   \n",
       "64  \\3\\Beginning with the spring SAT administratio...    NaN    NaN    NaN   \n",
       "65  NOTE: Data for 2005-06 and earlier years are f...    NaN    NaN    NaN   \n",
       "66  SOURCE: College Entrance Examination Board, Co...    NaN    NaN    NaN   \n",
       "\n",
       "       5      6      7      8      9      10     11     12     13     14  \\\n",
       "0   514.0  503.0  518.0  497.0  497.0  514.0  489.0  497.0  513.0  487.0   \n",
       "1   554.0  565.0  561.0  565.0  546.0  541.0  536.0  547.0  538.0  532.0   \n",
       "2   510.0  517.0  517.0  493.0  515.0  511.0  487.0  507.0  503.0  475.0   \n",
       "3   525.0  521.0  528.0  507.0  517.0  523.0  499.0  522.0  525.0  500.0   \n",
       "4   550.0  574.0  568.0  567.0  568.0  570.0  554.0  573.0  571.0  554.0   \n",
       "..    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "62    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "63    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "64    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "65    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "66    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "       15     16     17         18         19  \n",
       "0   495.0  511.0  484.0  48.055532  48.841478  \n",
       "1   545.0  538.0  533.0   6.700000   6.100000  \n",
       "2   509.0  503.0  482.0  54.200000  51.900000  \n",
       "3   523.0  527.0  502.0  36.400000  34.300000  \n",
       "4   568.0  569.0  551.0   4.200000   4.100000  \n",
       "..    ...    ...    ...        ...        ...  \n",
       "62    NaN    NaN    NaN        NaN        NaN  \n",
       "63    NaN    NaN    NaN        NaN        NaN  \n",
       "64    NaN    NaN    NaN        NaN        NaN  \n",
       "65    NaN    NaN    NaN        NaN        NaN  \n",
       "66    NaN    NaN    NaN        NaN        NaN  \n",
       "\n",
       "[67 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_2011_2012 = remove_nan(load_2011_2012)\n",
    "sat_1995_2015"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
